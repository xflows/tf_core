[
  {
    "model": "workflows.abstractwidget", 
    "fields": {
      "uid": "97e51e6b-74de-45b1-9539-784b300b1ac6", 
      "has_file": false, 
      "image": "", 
      "description": "These tokenizers divide strings into substrings using the string split() method.\r\n\r\nSpace Tokenizer - Tokenize a string using the space character as a delimiter, which is the same as s.split(' ').\r\nTab Tokenizer - Tokenize a string use the tab character as a delimiter, the same as s.split('\\t').\r\nChar Tokenizer - Tokenize a string into individual characters.  \r\nWhitespace Tokenizer - Tokenize a string on whitespace (space, tab, newline).\r\nBlankline Tokenizer - Tokenize a string, treating any sequence of blank lines as a delimiter. Blank lines are defined as lines containing no characters, except for space or tab characters.\r\nWord Punct Tokenizer - Tokenize a text into a sequence of alphabetic and non-alphabetic characters, using the regexp ``\\w+|[^\\w\\s]+``.", 
      "category": "b0ce2ce4-16e8-4f9c-9874-238066c20fea", 
      "interaction_view": "", 
      "streaming_visualization_view": "", 
      "treeview_image": "", 
      "is_streaming": false, 
      "windows_queue": false, 
      "static_image": "token_word_image.png", 
      "action": "nltk_simple_tokenizer", 
      "wsdl": "", 
      "name": "Simple Tokenizer", 
      "package": "tf_core.nltoolkit", 
      "visualization_view": "", 
      "post_interact_action": "", 
      "wsdl_method": "", 
      "has_progress_bar": false, 
      "order": 1, 
      "interactive": false
    }
  }, 
  {
    "model": "workflows.abstractinput", 
    "fields": {
      "widget": "97e51e6b-74de-45b1-9539-784b300b1ac6", 
      "name": "Type", 
      "short_name": "typ", 
      "uid": "18cb69d5-ebd5-41ed-98fb-4fb815ab7908", 
      "default": "wordpunct_tokenizer", 
      "required": true, 
      "multi": false, 
      "parameter_type": "select", 
      "variable": "type", 
      "parameter": true, 
      "order": 1, 
      "description": "Select a tokenizer.\r\n\r\nSpace Tokenizer - Tokenize a string using the space character as a delimiter, which is the same as s.split(' ').\r\n\r\nTab Tokenizer - Tokenize a string use the tab character as a delimiter, the same as s.split('\\t').\r\n\r\nChar Tokenizer - Tokenize a string into individual characters.  \r\n\r\nWhitespace Tokenizer - Tokenize a string on whitespace (space, tab, newline).\r\n\r\nBlankline Tokenizer - Tokenize a string, treating any sequence of blank lines as a delimiter. Blank lines are defined as lines containing no characters, except for space or tab characters.\r\n\r\nWord Punct Tokenizer - Tokenize a text into a sequence of alphabetic and non-alphabetic characters, using the regexp ``\\w+|[^\\w\\s]+``."
    }
  }, 
  {
    "model": "workflows.abstractoutput", 
    "fields": {
      "widget": "97e51e6b-74de-45b1-9539-784b300b1ac6", 
      "name": "Tokenizer", 
      "short_name": "tkn", 
      "variable": "tokenizer", 
      "uid": "7250fda2-a8d3-489f-8b98-2f018e17d5ae", 
      "order": 1, 
      "description": "A python dictionary containing the Tokenizer object and its arguments."
    }
  }, 
  {
    "model": "workflows.abstractoption", 
    "fields": {
      "uid": "157bf7c8-8c88-43b4-a68c-d87d0df86894", 
      "abstract_input": "18cb69d5-ebd5-41ed-98fb-4fb815ab7908", 
      "value": "tab_tokenizer", 
      "name": "Tab Tokenizer"
    }
  }, 
  {
    "model": "workflows.abstractoption", 
    "fields": {
      "uid": "4350c902-33e5-4fa4-a519-81f3009c819c", 
      "abstract_input": "18cb69d5-ebd5-41ed-98fb-4fb815ab7908", 
      "value": "whitespace_tokenizer", 
      "name": "Whitespace Tokenizer"
    }
  }, 
  {
    "model": "workflows.abstractoption", 
    "fields": {
      "uid": "91b732bf-f115-4d14-8c0d-e4a95773265f", 
      "abstract_input": "18cb69d5-ebd5-41ed-98fb-4fb815ab7908", 
      "value": "blankline_tokenizer", 
      "name": "Blankline Tokenizer"
    }
  }, 
  {
    "model": "workflows.abstractoption", 
    "fields": {
      "uid": "c10baa9e-9f02-485c-8ed9-d9ed37350eb4", 
      "abstract_input": "18cb69d5-ebd5-41ed-98fb-4fb815ab7908", 
      "value": "wordpunct_tokenizer", 
      "name": "WordPunct Tokenizer"
    }
  }, 
  {
    "model": "workflows.abstractoption", 
    "fields": {
      "uid": "c802dac6-9f9d-418a-ab7f-e45274d5ff78", 
      "abstract_input": "18cb69d5-ebd5-41ed-98fb-4fb815ab7908", 
      "value": "space_tokenizer", 
      "name": "Space Tokenizer"
    }
  }, 
  {
    "model": "workflows.abstractoption", 
    "fields": {
      "uid": "f463391e-5b1c-4cd4-a6e6-7edb08e75cfb", 
      "abstract_input": "18cb69d5-ebd5-41ed-98fb-4fb815ab7908", 
      "value": "char_tokenizer", 
      "name": "Char Tokenizer"
    }
  }
]