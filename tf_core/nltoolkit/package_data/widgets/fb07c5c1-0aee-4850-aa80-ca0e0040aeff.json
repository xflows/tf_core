[
  {
    "model": "workflows.abstractwidget", 
    "fields": {
      "uid": "fb07c5c1-0aee-4850-aa80-ca0e0040aeff", 
      "has_file": false, 
      "image": "", 
      "description": "The Regex Tokenizer splits a string into substrings using a regular expression.", 
      "category": "b0ce2ce4-16e8-4f9c-9874-238066c20fea", 
      "interaction_view": "", 
      "streaming_visualization_view": "", 
      "treeview_image": "", 
      "is_streaming": false, 
      "windows_queue": false, 
      "static_image": "token_word_image.png", 
      "action": "nltk_regex_tokenizer", 
      "wsdl": "", 
      "name": "Regex Tokenizer", 
      "package": "tf_core.nltoolkit", 
      "visualization_view": "", 
      "post_interact_action": "", 
      "wsdl_method": "", 
      "has_progress_bar": false, 
      "order": 1, 
      "interactive": false
    }
  }, 
  {
    "model": "workflows.abstractinput", 
    "fields": {
      "widget": "fb07c5c1-0aee-4850-aa80-ca0e0040aeff", 
      "name": "Discard empty", 
      "short_name": "dse", 
      "uid": "6101d30a-6ea2-48de-8c46-012f30a08f83", 
      "default": "", 
      "required": true, 
      "multi": false, 
      "parameter_type": "checkbox", 
      "variable": "discard_empty", 
      "parameter": true, 
      "order": 3, 
      "description": "True if any empty tokens `''`\r\n        generated by the tokenizer should be discarded.  Empty\r\n        tokens can only be generated if  Gaps is set."
    }
  }, 
  {
    "model": "workflows.abstractinput", 
    "fields": {
      "widget": "fb07c5c1-0aee-4850-aa80-ca0e0040aeff", 
      "name": "Regular Expression", 
      "short_name": "rgx", 
      "uid": "721ff51b-6bc2-4999-b561-3cacfb44560b", 
      "default": "\\p{L}+(-\\p{L}+)*", 
      "required": true, 
      "multi": false, 
      "parameter_type": "textarea", 
      "variable": "pattern", 
      "parameter": true, 
      "order": 1, 
      "description": "The pattern used to build this tokenizer.\r\n        (This pattern may safely contain capturing parentheses.)"
    }
  }, 
  {
    "model": "workflows.abstractinput", 
    "fields": {
      "widget": "fb07c5c1-0aee-4850-aa80-ca0e0040aeff", 
      "name": "Gaps", 
      "short_name": "gsp", 
      "uid": "9adea0e8-2983-4006-940a-938cfeb7d716", 
      "default": "", 
      "required": true, 
      "multi": false, 
      "parameter_type": "checkbox", 
      "variable": "gaps", 
      "parameter": true, 
      "order": 2, 
      "description": "True if this tokenizer's pattern should be used\r\n        to find separators between tokens; False if this\r\n        tokenizer's pattern should be used to find the tokens\r\n        themselves."
    }
  }, 
  {
    "model": "workflows.abstractoutput", 
    "fields": {
      "widget": "fb07c5c1-0aee-4850-aa80-ca0e0040aeff", 
      "name": "Tokenizer", 
      "short_name": "tkn", 
      "variable": "tokenizer", 
      "uid": "dbbb06d2-98d0-41e3-8395-9b66c912bf78", 
      "order": 1, 
      "description": "A python dictionary containing the Tokenizer object and its arguments."
    }
  }
]